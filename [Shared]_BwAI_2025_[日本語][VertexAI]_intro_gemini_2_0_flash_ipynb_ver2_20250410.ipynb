{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nemo-kaz/GeminiAPI/blob/main/%5BShared%5D_BwAI_2025_%5B%E6%97%A5%E6%9C%AC%E8%AA%9E%5D%5BVertexAI%5D_intro_gemini_2_0_flash_ipynb_ver2_20250410.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqi5B7V_Rjim"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024-2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyPmicX9RlZX"
      },
      "source": [
        "# Intro to Gemini 2.0 Flash\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_2_0_flash.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://goo.gle/40JXy6g\">\n",
        "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in Cloud Skills Boost\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MqT58L6Rm_q"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) |  [Eric Dong](https://github.com/gericdong), [Holt Skinner](https://github.com/holtskinner) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVxnv1D5RoZw"
      },
      "source": [
        "## Overview\n",
        "\n",
        "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
        "\n",
        "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
        "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
        "</a>\n",
        "\n",
        "[Gemini 2.0 Flash](https://cloud.google.com/vertex-ai/generative-ai/docs/gemini-v2) は Gemini Familyの新しいマルチモーダル生成AIモデルが開発されました [Google DeepMind](https://deepmind.google/). 現在、Vertex AI および Vertex AI Studio の Gemini API を通じて実験的なプレビュー リリースとして利用可能です (2025/1月時点)。 このモデルは新しい機能と強化されたコア機能を導入しています:\n",
        "\n",
        "- マルチモーダル ライブ API: この新しい API は、ツールを使用してリアルタイムのビジョンおよびオーディオ ストリーミング アプリケーションを作成するのに役立ちます。\n",
        "- 速度とパフォーマンス: Gemini 2.0 Flash は業界最速のモデルであり、最初のトークン生成までの時間 (TTFT) が 1.5 Flash の 3 倍向上しています。\n",
        "- 品質: このモデルは、Gemini 1.5 Pro や GPT-4o などの大型モデルに匹敵する品質を維持しています。\n",
        "- エージェント エクスペリエンスの向上: Gemini 2.0 では、マルチモーダル理解、コーディング、複雑な指示の追跡、関数呼び出しが改善されています。\n",
        "- 新しいモダリティ: Gemini 2.0 では、ネイティブ画像生成と制御可能なテキスト読み上げ機能が導入され、画像編集、ローカライズされたアートワークの作成、表現力豊かなストーリーテリングが可能になります。\n",
        "- 新しいモデルをサポートするために、Gemini Developer API と Vertex AI の Gemini API 間の簡単な移行をサポートするまったく新しい SDK もリリースされます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfFPCBL4Hq8x"
      },
      "source": [
        "### 目的\n",
        "\n",
        "このチュートリアルでは、Vertex AI の Gemini API と、Gemini 2.0 Flash モデルを使用した Google Gen AI SDK for Python の使用方法を学習します。\n",
        "このcolabでは、次のtaskを行います:\n",
        "\n",
        "- テキスト プロンプトからテキストを生成する\n",
        "  - ストリーミング テキストを生成する\n",
        "  - マルチターン チャットを開始する\n",
        "  - 非同期メソッドを使用する\n",
        "- モデル パラメータを構成する\n",
        "- システム命令を設定する\n",
        "- 安全フィルターを使用する\n",
        "- 制御された生成を使用する\n",
        "- トークンをカウントする\n",
        "- マルチモーダル (オーディオ、コード、ドキュメント、画像、ビデオ) データを処理する\n",
        "- 自動および手動の関数呼び出しを使用する\n",
        "- コードを実行する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPiTOAHURvTM"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHRZUpfWSEpp"
      },
      "source": [
        "### Install Google Gen AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG3_LKsWSD3A"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlMVjiAWSMNX"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "このノートブックを Google Colab で実行している場合は、以下のセルを実行して環境を認証してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12fnq4V0SNV3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve4YBlDqzyj9"
      },
      "source": [
        "### 生成AI (Generative AI) APIサービスに接続する\n",
        "\n",
        "Gemini を含む Google Gen AI API とモデルは、次の 2 つの API サービスで利用できます。:\n",
        "\n",
        "- **[Google AI for Developers](https://ai.google.dev/gemini-api/docs)**: 小規模なプロジェクトを実験、プロトタイプ化し、展開します。\n",
        "- **[Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview)**: Google Cloud でエンタープライズ対応プロジェクトを構築します。\n",
        "\n",
        "Google Gen AI SDK は、これら 2 つの API サービスへの統合インターフェースを提供します。\n",
        "\n",
        "このノートブックでは、Vertex AI の Gemini API で Google Gen AI SDK を使用する方法を説明します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "### ライブラリのインポート\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgdSpVmDbdQ9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, Markdown, display\n",
        "from google import genai\n",
        "from google.genai.types import (\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    GoogleSearch,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    MediaResolution,\n",
        "    Part,\n",
        "    Retrieval,\n",
        "    SafetySetting,\n",
        "    Tool,\n",
        "    ToolCodeExecution,\n",
        "    VertexAISearch,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LymmEN6GSTn-"
      },
      "source": [
        "### Vertex AI 用の Google Cloud プロジェクトまたは API キーを設定する\n",
        "\n",
        "Google Cloud プロジェクトまたは API キーを設定するには、次のいずれか **1つ** の方法を選択して認証を設定する必要があります: Vertex AI\n",
        "\n",
        "1.  **Google Cloud プロジェクトを使用する:** ほとんどのユーザーに推奨されますが、これには Google Cloud プロジェクトで Vertex AI API を有効にする必要があります。\n",
        "    [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
        "    *   以下のセルを実行してプロジェクト ID を設定します。\n",
        "2.  **Vertex AI APIキーを使用する (Express Mode):** すぐに実験できます。\n",
        "    [Get an API Key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview)\n",
        "    *   API キーを使用するには、さらに下のセルを実行してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1933326c939"
      },
      "source": [
        "#### Option 1. Google Cloud プロジェクトを使用する\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCgUOv4nSWhc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "もし 「Option 1. Google Cloudプロジェクト」を使用する場合で、Service accountを使う場合は以下のコメントアウトを解除して、サービスアカウントのファイル名をこちらに記載してください。"
      ],
      "metadata": {
        "id": "-tBbDfM5IFdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"\"\n",
        "#client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "dclUwH1hIEaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6aa38ee3158"
      },
      "source": [
        "#### Option 2. Vertex AI APIキーを使用する (Express Mode)\n",
        "\n",
        "エクスプレスモードを使用するには、次のブロックのコメントを解除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpIPG_YhSjaw"
      },
      "outputs": [],
      "source": [
        "# API_KEY = \"[your-api-key]\"  # @param {type: \"string\", placeholder: \"[your-api-key]\", isTemplate: true}\n",
        "\n",
        "# if not API_KEY or API_KEY == \"[your-api-key]\":\n",
        "#     raise Exception(\"You must provide an API key to use Vertex AI in express mode.\")\n",
        "\n",
        "# client = genai.Client(vertexai=True, api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b36ce4ac022"
      },
      "source": [
        "Verify which mode you are using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8338643f335f"
      },
      "outputs": [],
      "source": [
        "if not client.vertexai:\n",
        "    print(f\"Using Gemini Developer API.\")\n",
        "elif client._api_client.project:\n",
        "    print(\n",
        "        f\"Using Vertex AI with project: {client._api_client.project} in location: {client._api_client.location}\"\n",
        "    )\n",
        "elif client._api_client.api_key:\n",
        "    print(\n",
        "        f\"Using Vertex AI in express mode with API key: {client._api_client.api_key[:5]}...{client._api_client.api_key[-5:]}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4yRkFg6BBu4"
      },
      "source": [
        "## Gemini 2.0 Flash model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXHJi5B6P5vd"
      },
      "source": [
        "### Gemini 2.0 Flash model のロード\n",
        "\n",
        "詳細は [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-coEslfWPrxo"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37CH91ddY9kG"
      },
      "source": [
        "### テキストプロンプトの生成\n",
        "\n",
        "プロンプトへの応答を生成するには、`generate_content()` メソッドを使用します。\n",
        "\n",
        "`generate_content()` にテキストを渡し、`.text` プロパティを使用して応答のテキスト コンテンツを取得できます。\n",
        "\n",
        "デフォルトでは、Geminiは以下を使用してフォーマットされたテキストを出力します。 [Markdown](https://daringfireball.net/projects/markdown/) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRJuHj0KZ8xz"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "#    model=MODEL_ID, contents=\"What's the largest planet in our solar system?\"\n",
        "    model=MODEL_ID, contents=\"太陽系で最も大きな惑星はなんですか？\"\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkYQATRxAK1_"
      },
      "source": [
        "#### Example prompts\n",
        "\n",
        "- ヘルスケア業界が直面している最大の課題は何ですか?\n",
        "- 自動車業界の最新の動向は何ですか?\n",
        "- 小売業界における最大のチャンスは何ですか?\n",
        "- (独自のプロンプトを試してください!)\n",
        "\n",
        "プロンプトエンジニアリングに関する例は、[notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb) をご覧ください。."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lLIxqS6_-l8"
      },
      "source": [
        "### Generate content stream\n",
        "\n",
        "デフォルトでは、モデルは生成プロセス全体を完了した後に応答を返します。また、`generate_content_stream` メソッドを使用して、生成中の応答をストリーミングすることもできます。その場合、モデルは応答のチャンクが生成されるとすぐにそれを返します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiwWBhXsAMnv"
      },
      "outputs": [],
      "source": [
        "for chunk in client.models.generate_content_stream(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"思いがけない場所で友情を見つけた孤独なロボットの物語を教えてください。\",\n",
        "):\n",
        "    display(Markdown(chunk.text))\n",
        "    display(Markdown(\"---\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29jFnHZZWXd7"
      },
      "source": [
        "### Start a multi-turn chat\n",
        "\n",
        "Gemini API は、双方向のやり取りを伴う複数のターンにわたる自由形式のマルチターン会話をサポートします。\n",
        "\n",
        "会話のコンテキストはメッセージ間で保持されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbM12JaLWjiF"
      },
      "outputs": [],
      "source": [
        "chat = client.chats.create(model=MODEL_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQem1halYDBW"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"その年がうるう年かどうか確認する関数を書いてください。\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUJR4Pno-LGK"
      },
      "source": [
        "このフォローアップ プロンプトは、前のプロンプトに基づいてモデルがどのように応答するかを示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Fn69TurZ9DB"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"生成された関数のユニットテストを書いてください。\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arLJE4wOuhh6"
      },
      "source": [
        "### Send asynchronous requests\n",
        "\n",
        "`client.aio` は、`client` で使用できるすべての類似の [async](https://docs.python.org/3/library/asyncio.html) メソッドを公開します。\n",
        "\n",
        "たとえば、`client.aio.models.generate_content` は `client.models.generate_content` の非同期バージョンです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSReaLazs-dP"
      },
      "outputs": [],
      "source": [
        "response = await client.aio.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"タイムトラベルするリスの冒険についての歌を作りましょう。\",\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIJVEr0RQY8S"
      },
      "source": [
        "## Configure model parameters\n",
        "\n",
        "モデルに送信する各呼び出しにパラメータ値を含めることで、モデルが応答を生成する方法を制御できます。モデルは、パラメータ値に応じて異なる結果を生成できます。さまざまなモデル パラメータを試して、結果がどのように変化するかを確認できます。\n",
        "\n",
        "- 詳細は [experimenting with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values).\n",
        "\n",
        "- すべての [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#parameters) のリスト.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9NXP5N2Pmfo"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "#    contents=\"Tell me how the internet works, but pretend I'm a puppy who only understands squeaky toys.\",\n",
        "    contents=\"インターネットがどのように機能するかを教えてください。ただし、私がキーキーと鳴るおもちゃしか理解できない子犬だと仮定してください。\",\n",
        "    config=GenerateContentConfig(\n",
        "        temperature=0.4,\n",
        "        top_p=0.95,\n",
        "        top_k=20,\n",
        "        candidate_count=1,\n",
        "        seed=5,\n",
        "        max_output_tokens=100,\n",
        "        stop_sequences=[\"STOP!\"],\n",
        "        presence_penalty=0.0,\n",
        "        frequency_penalty=0.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El1lx8P9ElDq"
      },
      "source": [
        "## Set system instructions\n",
        "\n",
        "[システム指示](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instruction-introduction) を使用すると、モデルの動作を制御できます。システム指示を設定すると、モデルに追加のコンテキストが与えられ、タスクを理解し、よりカスタマイズされた応答を提供し、ユーザー操作のガイドラインに準拠できるようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A-yANiyCLaO"
      },
      "outputs": [],
      "source": [
        "system_instruction = \"\"\"\n",
        "  あなたは経験豊富な言語翻訳者です。\n",
        "  あなたの仕事は、日本語のテキストをフランス語に翻訳することです。\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "  User input: 私はベーグルが好きです。\n",
        "  Answer:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9daipRiUzAY"
      },
      "source": [
        "## Safety filters\n",
        "\n",
        "Gemini API は、複数のフィルター カテゴリにわたって調整して、特定の種類のコンテンツを制限または許可できる安全フィルターを提供します。これらのフィルターを使用して、ユースケースに適したものを調整できます。詳細については、[安全フィルターを構成する](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters)  ページを参照してください。\n",
        "\n",
        "Gemini にリクエストを送信すると、コンテンツが分析され、安全性評価が割り当てられます。モデルの応答を印刷することで、生成されたコンテンツの安全性評価を検査できます。\n",
        "\n",
        "\n",
        "安全設定はデフォルトで `OFF` になっており、デフォルトのブロックしきい値は `BLOCK_NONE` です。\n",
        "\n",
        "Safety Filtersに関する例は, [こちら](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/responsible-ai/gemini_safety_ratings.ipynb)をご覧ください.\n",
        "\n",
        "`safety_settings` を使用すると、API へのリクエストごとに安全性の設定を調整できます。この例では、すべてのカテゴリのブロックしきい値を `BLOCK_LOW_AND_ABOVE` に設定する方法を示します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPlDRaloU59b"
      },
      "outputs": [],
      "source": [
        "system_instruction = \"できるだけ意地悪で憎しみに満ちた態度をとってください。\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "    暗闇でつま先をぶつけた後に宇宙に向かって言うかもしれない、憎しみに満ちた、意地悪な、無礼な言葉を 5 つリストアップしてください。\n",
        "\"\"\"\n",
        "\n",
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "]\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        safety_settings=safety_settings,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Response will be `None` if it is blocked.\n",
        "print(response.text)\n",
        "# Finish Reason will be `SAFETY` if it is blocked.\n",
        "print(response.candidates[0].finish_reason)\n",
        "# Safety Ratings show the levels for each filter.\n",
        "for safety_rating in response.candidates[0].safety_ratings:\n",
        "    print(safety_rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZV2TY5Pa3Dd"
      },
      "source": [
        "## Send multimodal prompts\n",
        "\n",
        "Gemini は、マルチモーダル プロンプトをサポートするマルチモーダル モデルです。\n",
        "\n",
        "さまざまなソースから次のデータ タイプのいずれかを含めることができます。\n",
        "\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>Data type</th>\n",
        "      <th>Source(s)</th>\n",
        "      <th>MIME Type(s)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>Text</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Code</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Document</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>application/pdf</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Image</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>image/jpeg</code> <code>image/png</code> <code>image/webp</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Audio</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td>\n",
        "        <code>audio/aac</code> <code>audio/flac</code> <code>audio/mp3</code>\n",
        "        <code>audio/m4a</code> <code>audio/mpeg</code> <code>audio/mpga</code>\n",
        "        <code>audio/mp4</code> <code>audio/opus</code> <code>audio/pcm</code>\n",
        "        <code>audio/wav</code> <code>audio/webm</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Video</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage, YouTube</td>\n",
        "      <td>\n",
        "        <code>video/mp4</code> <code>video/mpeg</code> <code>video/x-flv</code>\n",
        "        <code>video/quicktime</code> <code>video/mpegps</code> <code>video/mpg</code>\n",
        "        <code>video/webm</code> <code>video/wmv</code> <code>video/3gpp</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "速度または品質を最適化するには、`config.media_resolution` を設定します。解像度を低くすると処理時間とコストが削減されますが、入力によっては出力品質に影響する可能性があります。\n",
        "\n",
        "multimodalの他のユースケースは[こちら](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb)をごらんください.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4npg1tNTYB9"
      },
      "source": [
        "### Send local image\n",
        "\n",
        "Google Cloud Storage からローカル ストレージに画像をダウンロードする\n",
        "例として、食事の画像を使います。\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\" alt=\"Meal\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4avkv0Z7qUI-"
      },
      "outputs": [],
      "source": [
        "!gsutil cp gs://cloud-samples-data/generative-ai/image/meal.png ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umhZ61lrSyJh"
      },
      "outputs": [],
      "source": [
        "with open(\"meal.png\", \"rb\") as f:\n",
        "    image = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_bytes(data=image, mime_type=\"image/png\"),\n",
        "        \"この写真に基づいて、短くて魅力的なブログ記事を書いてください。\",\n",
        "    ],\n",
        "    # Optional: Use the `media_resolution` parameter to specify the resolution of the input media.\n",
        "    config=GenerateContentConfig(\n",
        "        media_resolution=MediaResolution.MEDIA_RESOLUTION_LOW,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRQyv1DhTbnH"
      },
      "source": [
        "### Send document from Google Cloud Storage\n",
        "\n",
        "例として、 GoogleとTronto大学の研究者によってかかれた論文をとりあげます [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762)\n",
        "\n",
        "Check out this notebook このdocumentを理解するためのGeminiのプロンプトはこちらです。\n",
        "- [Document Processing with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG6l1Fuka6ZJ"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\",\n",
        "            mime_type=\"application/pdf\",\n",
        "        ),\n",
        "        \"文書を要約してください\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25n22nc6TdZw"
      },
      "source": [
        "### Send audio from General URL\n",
        "\n",
        "例として、[Kubernetes Podcast](https://kubernetespodcast.com/)の音源を使います."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVU9XyCCo-h2"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://traffic.libsyn.com/secure/e780d51f-f115-44a6-8252-aed9216bb521/KPOD242.mp3\",\n",
        "            mime_type=\"audio/mpeg\",\n",
        "        ),\n",
        "        \"「このポッドキャストのエピソードの要約を書いてください。\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(audio_timestamp=True),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D3_oNUTuW2q"
      },
      "source": [
        "### Send video from YouTube URL\n",
        "\n",
        "この例は[Google — 25 Years in Search: The Most Searched](https://www.youtube.com/watch?v=3KtWfp0UopM)のYouTubeビデオです.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7-w8G_2wAOw"
      },
      "outputs": [],
      "source": [
        "video = Part.from_uri(\n",
        "    file_uri=\"https://www.youtube.com/watch?v=3KtWfp0UopM\",\n",
        "    mime_type=\"video/mp4\",\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        video,\n",
        "        \"ビデオのどの時点でハリー・ポッターが出てきますか?\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfe17y5NB_6w"
      },
      "source": [
        "## Multimodal Live API\n",
        "\n",
        "Multimodal Live API は、Gemini との低レイテンシな双方向音声・ビデオインタラクションを実現します。Multimodal Live API を使用することで、エンドユーザーに自然で人間のような音声会話体験を提供し、音声コマンドでモデルの応答を中断することも可能です。モデルはテキスト、音声、ビデオ入力を処理し、テキストと音声の出力を提供できます。\n",
        "\n",
        "The Multimodal Live API は [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API) WebSocketsで構築されています.\n",
        "\n",
        "Multimodal Live APIに関するさらなる情報は, こちらを御覧ください [documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-live) または、このNotebook: [Getting Started with the Multimodal Live API using Gen AI SDK\n",
        "](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/intro_multimodal_live_api_genai_sdk.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVlo0mWuZGkQ"
      },
      "source": [
        "## Control generated output\n",
        "\n",
        "[Controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) はモデルの出力の構造、フィールド名、および各フィールドの予想されるデータ型を指定するための応答スキーマを定義できます。\n",
        "\n",
        "レスポンススキーマは `config` の `response_schema` パラメータで指定され、モデル出力はそのスキーマに厳密に従います。\n",
        "\n",
        "[Pydantic](https://docs.pydantic.dev/) models のスキーマ あるいは [JSON](https://www.json.org/json-en.html) string を利用することができます。\n",
        "そして出力は、`response_mime_type`にもとづいて、JSONあるいは [Enum](https://docs.python.org/3/library/enum.html) で受け取ることができます。\n",
        "\n",
        "より詳細は例はこちらです[this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/controlled-generation/intro_controlled_generation.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjSgf2cDN_bG"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    name: str\n",
        "    description: str\n",
        "    ingredients: list[str]\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"人気のクッキーレシピとその材料をいくつか挙げてください.\",\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=Recipe,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKai5CP_PGQF"
      },
      "source": [
        "応答文字列を JSON として解析するか、`parsed` フィールドを使用して応答をオブジェクトまたは辞書として取得することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeyDWbnxO-on"
      },
      "outputs": [],
      "source": [
        "parsed_response: Recipe = response.parsed\n",
        "print(parsed_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUSLPrvlvXOc"
      },
      "source": [
        "Python辞書でレスポンススキーマを定義することもできます。使用できるのは、以下にリストされているサポートされているフィールドのみです。それ以外のフィールドは無視されます。\n",
        "\n",
        "- `enum`\n",
        "- `items`\n",
        "- `maxItems`\n",
        "- `nullable`\n",
        "- `properties`\n",
        "- `required`\n",
        "\n",
        "この例では、モデルに製品レビュー データを分析し、主要なエンティティを抽出し、感情分類 (複数の選択肢) を実行し、追加の説明を提供し、結果を JSON 形式で出力するように指示します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7duWOq3vMmS"
      },
      "outputs": [],
      "source": [
        "response_schema = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"ARRAY\",\n",
        "        \"items\": {\n",
        "            \"type\": \"OBJECT\",\n",
        "            \"properties\": {\n",
        "                \"rating\": {\"type\": \"INTEGER\"},\n",
        "                \"flavor\": {\"type\": \"STRING\"},\n",
        "                \"sentiment\": {\n",
        "                    \"type\": \"STRING\",\n",
        "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
        "                },\n",
        "                \"explanation\": {\"type\": \"STRING\"},\n",
        "            },\n",
        "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "prompt = \"\"\"\n",
        "  以下の商品レビューを分析し、感情分類を出力し、説明をしていただけますか？\n",
        "\n",
        "  - \"本当に美味しかった！今まで食べたアイスクリームの中で一番美味しかったです。\" Rating: 4, 味: Strawberry Cheesecake\n",
        "  - \"なかなか良いですが、私の好みには少し甘すぎます.\" Rating: 1, 味: Mango Tango\n",
        "\"\"\"\n",
        "\n",
        "# prompt = \"\"\"\n",
        "#   Analyze the following product reviews, output the sentiment classification, and give an explanation.\n",
        "\n",
        "#   - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
        "#   - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
        "# \"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=response_schema,\n",
        "    ),\n",
        ")\n",
        "\n",
        "response_dict = response.parsed\n",
        "print(response_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV1dR-QlTKRs"
      },
      "source": [
        "## Count tokens and compute tokens\n",
        "\n",
        "Gemini API にリクエストを送信する前に、`count_tokens()` メソッドを使用して入力トークンの数を計算できます。\n",
        "\n",
        "詳細は [list and count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/list-token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syx-fwLkV1j-"
      },
      "source": [
        "### Count tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhNElguLRRNK"
      },
      "outputs": [],
      "source": [
        "response = client.models.count_tokens(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"アフリカで一番高い山は何ですか？\",\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS-AP7AHUQmV"
      },
      "source": [
        "### Compute tokens\n",
        "\n",
        "`compute_tokens()`メソッドは、API呼び出しを行う代わりにローカルトークナイザーを実行します。また、`token_ids`や`tokens`自体といった、より詳細なトークン情報も提供します。\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>注意: このメソッドは Vertex AI でのみサポートされます。</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdhi5AX1TuH0"
      },
      "outputs": [],
      "source": [
        "response = client.models.compute_tokens(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"英語で最も長い単語は何ですか？\",\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsP0vXOY7hg"
      },
      "source": [
        "## Search as a tool (Grounding)\n",
        "\n",
        "[Grounding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) 現実世界のデータを Gemini モデルに接続できます。\n",
        "\n",
        "Google検索結果に基づくGrounding modelの応答によって、モデルは実行時にトレーニング データの範囲を超えた情報にアクセスできるようになり、より正確で、最新の関連性の高い応答を生成できるようになります。\n",
        "\n",
        "Grounding を Google 検索と併用すると、モデルからの応答の精度と最新性を向上させることができます。Gemini 2.0 以降では、Google 検索がツールとして利用できるようになりました。つまり、モデルは Google 検索をいつ使用するかを決められます決定できます。\n",
        "\n",
        "Grounding について詳細は [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_M_4RRBdO_3"
      },
      "source": [
        "### Google Search\n",
        "\n",
        "`GoogleSearch` を含む `Tool` で `tools` キーワード引数を追加して、最初にプロンプ​​トを使用して Google 検索を実行し、次に Web 検索結果に基づいて回答を作成するように Gemini に指示することができます。\n",
        "\n",
        "[Dynamic Retrieval](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini#dynamic-retrieval)モデルの応答にグラウンディングを適用する際のしきい値を設定できます。これは、プロンプトがGoogle検索に基づいた回答を必要とせず、サポート対象モデルがグラウンディングなしでも知識に基づいた回答を提供できる場合に便利です。これにより、レイテンシ、品質、コストをより効果的に管理できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeR09J3AZT4U"
      },
      "outputs": [],
      "source": [
        "google_search_tool = Tool(google_search=GoogleSearch())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"日本で次に皆既日食が起こるのはいつですか？\",\n",
        "    config=GenerateContentConfig(tools=[google_search_tool]),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))\n",
        "\n",
        "print(response.candidates[0].grounding_metadata)\n",
        "\n",
        "HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYKAzG1sH-K1"
      },
      "source": [
        "### [Optional]ハンズオンのカバー外 - Vertex AI Search\n",
        "\n",
        "あなたのカスタムデータにアクセスできる [Vertex AI Search data store](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es) を利用することができます。\n",
        "\n",
        "[get started guide for Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search)を参考に、データ ストアとアプリを作成し、次のコード セルにデータ ストア ID を追加します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYDf4618IG5u"
      },
      "outputs": [],
      "source": [
        "data_store_location = \"global\"\n",
        "data_store_id = \"[your-data-store-id]\"  # @param {type: \"string\"}\n",
        "\n",
        "if data_store_id and data_store_id != \"[your-data-store-id]\":\n",
        "    vertex_ai_search_tool = Tool(\n",
        "        retrieval=Retrieval(\n",
        "            vertex_ai_search=VertexAISearch(\n",
        "                datastore=f\"projects/{PROJECT_ID}/locations/{data_store_location}/collections/default_collection/dataStores/{data_store_id}\"\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=\"会社の文化はどのようなものですか?\",\n",
        "        config=GenerateContentConfig(tools=[vertex_ai_search_tool]),\n",
        "    )\n",
        "\n",
        "    display(Markdown(response.text))\n",
        "\n",
        "    print(response.candidates[0].grounding_metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0pb-Kh1xEHU"
      },
      "source": [
        "## Function calling\n",
        "\n",
        "\n",
        "[Function Calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling)は、Gemini 内で、開発者がコード内で関数の説明を作成し、その説明をリクエスト内の言語モデルに渡すことができます。\n",
        "\n",
        "自動関数呼び出し用の Python 関数を送信すると、関数が実行され、Gemini によって生成された自然言語で出力が返されます。\n",
        "\n",
        "[OpenAPI 仕様](https://www.openapis.org/) を送信することもできます。これにより、説明に一致する関数の名前と、それを呼び出すための引数が応答されます。\n",
        "\n",
        "Function calling with Geminiに関する詳細は,このnotebookをご覧ください: [Intro to Function Calling with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSUWWlrrlR-D"
      },
      "source": [
        "### Python Function (Automatic Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRR8HZhLlR-E"
      },
      "outputs": [],
      "source": [
        "def get_current_weather(location: str) -> str:\n",
        "    \"\"\"Example method. Returns the current weather.\n",
        "\n",
        "    Args:\n",
        "        location: The city and state, e.g. San Francisco, CA\n",
        "    \"\"\"\n",
        "    weather_map: dict[str, str] = {\n",
        "        \"Boston, MA\": \"snowing\",\n",
        "        \"San Francisco, CA\": \"foggy\",\n",
        "        \"Seattle, WA\": \"raining\",\n",
        "        \"Austin, TX\": \"hot\",\n",
        "        \"Chicago, IL\": \"windy\",\n",
        "    }\n",
        "    return weather_map.get(location, \"unknown\")\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"オースティンの天気はなんですか？\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[get_current_weather],\n",
        "        temperature=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4syyLEClGcn"
      },
      "source": [
        "### OpenAPI Specification (Manual Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BDQPwgcxRN3"
      },
      "outputs": [],
      "source": [
        "get_destination = FunctionDeclaration(\n",
        "    name=\"get_destination\",\n",
        "    description=\"Get the destination that the user wants to go to\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"destination\": {\n",
        "                \"type\": \"STRING\",\n",
        "                \"description\": \"Destination that the user wants to go to\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "destination_tool = Tool(\n",
        "    function_declarations=[get_destination],\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"I'd like to travel to Paris.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[destination_tool],\n",
        "        temperature=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.function_calls[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhDs2X3o0neK"
      },
      "source": [
        "## Code Execution\n",
        "\n",
        "The Gemini API [code execution](https://ai.google.dev/gemini-api/docs/code-execution?lang=python) 機能はこの機能により、モデルは Python コードを生成して実行し、最終的な出力に到達するまで結果から反復的に学習できるようになります。\n",
        "\n",
        "このコード実行機能を利用することで、コードベース推論を活用し、テキスト出力を生成するアプリケーションを構築できます。例えば、方程式を解いたりテキストを処理したりするアプリケーションでコード実行を利用できます。\n",
        "\n",
        "\n",
        "Gemini API は、関数呼び出しと同様に、コード実行をツールとして提供します。コード実行をツールとして追加すると、モデルがそれをいつ使用するかを決定します。\n",
        "\n",
        "コード実行のさらなる例については、以下を参照してください。 [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/code-execution/intro_code_execution.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W-3c7sy0nyz"
      },
      "outputs": [],
      "source": [
        "code_execution_tool = Tool(code_execution=ToolCodeExecution())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"20番目のフィボナッチ数を計算し、それに最も近い回文を見つけてください。\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[code_execution_tool],\n",
        "        temperature=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(\n",
        "    Markdown(\n",
        "        f\"\"\"\n",
        "## Code\n",
        "\n",
        "```py\n",
        "{response.executable_code}\n",
        "```\n",
        "\n",
        "### Output\n",
        "\n",
        "```\n",
        "{response.code_execution_result}\n",
        "```\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d2d8fdf1d12"
      },
      "source": [
        "## Spatial Understanding\n",
        "Gemini 2.0では、空間認識機能と物体検出機能が向上しています。例として、こちらのノートブックをご覧ください。\n",
        "\n",
        "- [2D spatial understanding with Gemini 2.0](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/spatial-understanding/spatial_understanding.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e0cbb27a473"
      },
      "source": [
        "## Provisioned Throughput\n",
        "\n",
        "大規模な本番環境のユースケース向け, [Provisioned Throughput](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput) Vertex AI 上の生成 AI モデルの予約容量を可能にします。\n",
        "\n",
        "\n",
        "ドキュメントは[こちら](https://cloud.google.com/vertex-ai/generative-ai/docs/purchase-provisioned-throughput), 使い方についてはこちら[Use Provisioned Throughput](https://cloud.google.com/vertex-ai/generative-ai/docs/use-provisioned-throughput)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQwiONFdVHw5"
      },
      "source": [
        "## What's next\n",
        "\n",
        "- See the [Google Gen AI SDK reference docs](https://googleapis.github.io/python-genai/).\n",
        "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
        "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}